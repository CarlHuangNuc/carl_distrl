defaults:
  - default
  - _self_

# ===================
# ====== basic ======
# ===================
parallel: "host" # "single" or "host" or "worker"
sync_mode: "async"  # "async", "sync"
save_path: '/mnt/huangke1/logs/host'
aggregated_save_path: '/mnt/huangke1/logs/aggregate'
synthetic: False

# ===================
# ====== path =======
# ===================
android_avd_home: '/mnt/huangke1/.android/avd'
emulator_path: '/mnt/huangke1/.android/emulator/emulator'
adb_path: '/mnt/huangke1/.android/platform-tools/adb'
cache_dir: '/mnt/huangke1/.cache'
assets_path: '/mnt/huangke1/carl_distrl/assets/task_set'

# ===================
# ====== model ======
# ===================
policy_lm: '/mnt/huangke1/auto-UI/cooelf/Auto-UI/Auto-UI-Base'
critic_lm: '/mnt/huangke1/auto-UI/roberta-base'

# ===================
# ====== train ======
# ===================
train_iterations: 400
train_time: 100 # (in minutes) -1 for unlimited
save_freq: 1

capacity: 10000 # replay buffer size
batch_size: 2 # replay buffer sample batch size
warmup_iter: 0 # how many iterations to only collect data and evaluate before training

#start_checkpoint_path: '/home/distrl/models/ckpts/webshop-off2on-digirl'
collect_num: 128
# collect_time: null

offline_data_path: null
#offline_data_path: '/home/<usrname>/data/distrl_data/warmup_trajectories_penalty.pt'
#offline_actor_iterations: 30
#offline_critic_iterations: 20
#offline_trajectory_critic_iterations: 20

# ===================
# ===== remote ======
# ===================
worker_temp_path: '/mnt/huangke1/logs/worker'
worker_run_path: "/mnt/huangke1/carl_distrl/scripts"
worker_ips: [worker_ip1]
worker_username: root
num_threads: 1

# ===================
# ===== distrl ======
# ===================
use_retrace: True
use_entropy: False
use_dper: False
dper_w1: 50
