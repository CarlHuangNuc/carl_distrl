defaults:
  - default
  - _self_

# ===================
# ====== basic ======
# ===================
parallel: "single" # "single" or "host" or "worker"
sync_mode: "sync"  # "async", "sync"
save_path: '/mnt/huangke1/logs/single/host'
aggregated_save_path: '/mnt/huangke1/logs/single/aggregate'
synthetic: False

# ===================
# ====== path =======
# ===================
android_avd_home: '/mnt/huangke1/.android/avd'
emulator_path: '/mnt/huangke1/.android/emulator/emulator'
adb_path: '/mnt/huangke1/.android/platform-tools/adb'
cache_dir: '/mnt/huangke1/.cache'
assets_path: '/mnt/huangke1/carl_distrl/assets/task_set'

# ===================
# ====== model ======
# ===================
policy_lm: '/mnt/huangke1/auto-UI/cooelf/Auto-UI/Auto-UI-Base'
critic_lm: '/mnt/huangke1/auto-UI/roberta-base'

# ===================
# ====== train ======
# ===================
train_iterations: 400
train_time: 100 # (in minutes) -1 for unlimited
save_freq: 1

capacity: 10000 # replay buffer size
batch_size: 2 # replay buffer sample batch size
warmup_iter: 0 # how many iterations to only collect data and evaluate before training

start_checkpoint_path: '/mnt/huangke1/huawei/backup_data/trainer_current_policy.pt'
collect_num: 128

offline_data_path: null
#offline_data_path: '/home/<usrname>/data/distrl_data/warmup_trajectories_penalty.pt'
#offline_actor_iterations: 30
#offline_critic_iterations: 20
#offline_trajectory_critic_iterations: 20

# ===================
# ===== collect =====
# ===================
collect_iterations: 1
bsize: 1 # number of emulators parallelly on the machine
rollout_size: 2 # how many trajectories to collect between training iterations (should be multiple of bsize)
avd_name: 'test_Android'
save_images: False
